{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0sKH7tuaD9lAnC6uB+Hb7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marriyam/DataScience/blob/Marriyam/internship2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "3OoUeyG-NxJ1",
        "outputId": "3f07017a-ede8-4379-c3fb-4f141ca7c72d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-704fc7b1-0e9e-447a-bcfd-92bcc9e4b40a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-704fc7b1-0e9e-447a-bcfd-92bcc9e4b40a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving loan.csv to loan.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "upload = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVNFc2BJX1Zi",
        "outputId": "4cfde7cb-363c-4cce-d094-a6ecb4fa91ef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 41 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 55.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=a293ceec10df438bcb9625ceec18ed5f4f8f5030bc2d313a44f87480cae10dff\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#first load all the useful libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *"
      ],
      "metadata": {
        "id": "F00aTuToYNYD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create the spark session\n",
        "from pyspark import SparkConf, SparkContext\n",
        "conf=SparkConf()\n",
        "conf.set(\"spark.executor.memory\", \"4g\")\n",
        "conf.set(\"spark.driver.memory\", \"4g\")\n",
        "conf.set(\"spark.cores.max\", \"2\")\n",
        "conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
        "spark = SparkSession.builder.appName(\"Loan Fraud Detection\").config(\"spark.jars\", \"flow_utilities/postgresql-42.2.5.jar\").getOrCreate()"
      ],
      "metadata": {
        "id": "ZAKaX3bPYQzS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading data from Colab\n",
        "df = spark.read.csv('/content/loan.csv',header = True)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91hhUET7ZMda",
        "outputId": "b66fae0c-f181-4ffb-9920-c416f7f6e91c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------+---------------------+--------------------+---------------------+-------------------------------------------+--------------------+---------------+-------------+---------------+-------------------------------------+--------------------+-------------------+\n",
            "| loan_application_id|applicant_id|Months_loan_taken_for|             Purpose|Principal_loan_amount|EMI_rate_in_percentage_of_disposable_income|            Property|Has_coapplicant|Has_guarantor|Other_EMI_plans|Number_of_existing_loans_at_this_bank|        Loan_history|high_risk_applicant|\n",
            "+--------------------+------------+---------------------+--------------------+---------------------+-------------------------------------------+--------------------+---------------+-------------+---------------+-------------------------------------+--------------------+-------------------+\n",
            "|d68d975e-edad-11e...|     1469590|                    6|electronic equipment|              1169000|                                          4|         real estate|              0|            0|           null|                                    2|critical/pending ...|                  0|\n",
            "|d68d989e-edad-11e...|     1203873|                   48|electronic equipment|              5951000|                                          2|         real estate|              0|            0|           null|                                    1|existing loans pa...|                  1|\n",
            "|d68d995c-edad-11e...|     1432761|                   12|           education|              2096000|                                          2|         real estate|              0|            0|           null|                                    1|critical/pending ...|                  0|\n",
            "|d68d99fc-edad-11e...|     1207582|                   42|                FF&E|              7882000|                                          2|building society ...|              0|            1|           null|                                    1|existing loans pa...|                  0|\n",
            "|d68d9a92-edad-11e...|     1674436|                   24|         new vehicle|              4870000|                                          3|                null|              0|            0|           null|                                    2|delay in paying o...|                  1|\n",
            "|d68d9b1e-edad-11e...|     1213971|                   36|           education|              9055000|                                          2|                null|              0|            0|           null|                                    1|existing loans pa...|                  0|\n",
            "|d68d9bb4-edad-11e...|     1428822|                   24|                FF&E|              2835000|                                          3|building society ...|              0|            0|           null|                                    1|existing loans pa...|                  0|\n",
            "|d68d9c40-edad-11e...|     1705739|                   36|        used vehicle|              6948000|                                          2|        car or other|              0|            0|           null|                                    1|existing loans pa...|                  0|\n",
            "|d68d9cc2-edad-11e...|     1715169|                   12|electronic equipment|              3059000|                                          2|         real estate|              0|            0|           null|                                    1|existing loans pa...|                  0|\n",
            "|d68d9d4e-edad-11e...|     1722991|                   30|         new vehicle|              5234000|                                          4|        car or other|              0|            0|           null|                                    2|critical/pending ...|                  1|\n",
            "|d68d9dda-edad-11e...|     1719964|                   12|         new vehicle|              1295000|                                          3|        car or other|              0|            0|           null|                                    1|existing loans pa...|                  1|\n",
            "|d68d9e66-edad-11e...|     1818043|                   48|            business|              4308000|                                          3|building society ...|              0|            0|           null|                                    1|existing loans pa...|                  1|\n",
            "|d68d9ef2-edad-11e...|     1231297|                   12|electronic equipment|              1567000|                                          1|        car or other|              0|            0|           null|                                    1|existing loans pa...|                  0|\n",
            "|d68d9f74-edad-11e...|     1172292|                   24|         new vehicle|              1199000|                                          4|        car or other|              0|            0|           null|                                    2|critical/pending ...|                  1|\n",
            "|d68da000-edad-11e...|     1154808|                   15|         new vehicle|              1403000|                                          2|        car or other|              0|            0|           null|                                    1|existing loans pa...|                  0|\n",
            "|d68da08c-edad-11e...|     1648542|                   24|electronic equipment|              1282000|                                          4|        car or other|              0|            0|           null|                                    1|existing loans pa...|                  1|\n",
            "|d68da118-edad-11e...|     1193245|                   24|electronic equipment|              2424000|                                          4|building society ...|              0|            0|           null|                                    2|critical/pending ...|                  0|\n",
            "|d68da19a-edad-11e...|     1740408|                   30|            business|              8072000|                                          2|        car or other|              0|            0|           bank|                                    3|no loans taken/al...|                  0|\n",
            "|d68da226-edad-11e...|     1250076|                   24|        used vehicle|             12579000|                                          4|                null|              0|            0|           null|                                    1|existing loans pa...|                  1|\n",
            "|d68da2b2-edad-11e...|     1616625|                   24|electronic equipment|              3430000|                                          3|        car or other|              0|            0|           null|                                    1|existing loans pa...|                  0|\n",
            "+--------------------+------------+---------------------+--------------------+---------------------+-------------------------------------------+--------------------+---------------+-------------+---------------+-------------------------------------+--------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**String Indexer for String Values**"
      ],
      "metadata": {
        "id": "zCVjIKKxDyHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
        "\n",
        "S_indexer=StringIndexer(inputCols=['loan_application_id','applicant_id','Months_loan_taken_for','Purpose','Principal_loan_amount','EMI_rate_in_percentage_of_disposable_income','Property','Has_coapplicant','Has_guarantor','Other_EMI_plans','Number_of_existing_loans_at_this_bank','Loan_history'], outputCols=['loan_application_id_indexed','applicant_id_indexed','Months_loan_taken_for_indexed','Purpose_indexed','Principal_loan_amount_indexed','EMI_rate_in_percentage_of_disposable_income_indexed','Property_indexed','Has_coapplicant_indexed','Has_guarantor_indexed','Other_EMI_plans_indexed','Number_of_existing_loans_at_this_bank_indexed','Loan_history_indexed'])\n",
        "df=S_indexer.fit(df).transform(df)\n"
      ],
      "metadata": {
        "id": "OssW05DUYB2a"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select('Principal_loan_amount', 'Principal_loan_amount_Indexed', 'Has_coapplicant', 'Has_coapplicant_Indexed' ).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFZp1LrqYEMF",
        "outputId": "ddf1f537-e61e-4be6-bcbe-97cad7ea3aa2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+-----------------------------+---------------+-----------------------+\n",
            "|Principal_loan_amount|Principal_loan_amount_Indexed|Has_coapplicant|Has_coapplicant_Indexed|\n",
            "+---------------------+-----------------------------+---------------+-----------------------+\n",
            "|              1169000|                          8.0|              0|                    0.0|\n",
            "|              5951000|                        736.0|              0|                    0.0|\n",
            "|              2096000|                        353.0|              0|                    0.0|\n",
            "|              7882000|                        849.0|              0|                    0.0|\n",
            "|              4870000|                        695.0|              0|                    0.0|\n",
            "|              9055000|                        888.0|              0|                    0.0|\n",
            "|              2835000|                        491.0|              0|                    0.0|\n",
            "|              6948000|                        795.0|              0|                    0.0|\n",
            "|              3059000|                        518.0|              0|                    0.0|\n",
            "|              5234000|                        710.0|              0|                    0.0|\n",
            "|              1295000|                         18.0|              0|                    0.0|\n",
            "|              4308000|                        658.0|              0|                    0.0|\n",
            "|              1567000|                        255.0|              0|                    0.0|\n",
            "|              1199000|                          9.0|              0|                    0.0|\n",
            "|              1403000|                        205.0|              0|                    0.0|\n",
            "|              1282000|                         16.0|              0|                    0.0|\n",
            "|              2424000|                        422.0|              0|                    0.0|\n",
            "|              8072000|                        858.0|              0|                    0.0|\n",
            "|             12579000|                        155.0|              0|                    0.0|\n",
            "|              3430000|                        565.0|              0|                    0.0|\n",
            "+---------------------+-----------------------------+---------------+-----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One-Hot Encoding**"
      ],
      "metadata": {
        "id": "4q3ATaBoaJmi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One Hot Encoding**"
      ],
      "metadata": {
        "id": "Z2GHCt_WD22T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OHE=OneHotEncoder(inputCols=['loan_application_id_indexed', 'Purpose_indexed', 'Property_indexed', 'Other_EMI_plans_indexed', 'Loan_history_indexed'], outputCols=['loan_application_id_indexed_OHE', 'Purpose_indexed_OHE', 'Property_indexed_OHE', 'Other_EMI_plans_indexed_OHE', 'Loan_history_indexed_OHE']).fit(df)\n",
        "O_H_E=OHE.transform(df)"
      ],
      "metadata": {
        "id": "qe2E0PyvaGYI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "O_H_E.select('Purpose', 'Purpose_indexed', 'Purpose_indexed_OHE').show() "
      ],
      "metadata": {
        "id": "GEpLb5PxaGhz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b4bc3fc-27d0-4010-f37a-357d7f22a9dd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------------+-------------------+\n",
            "|             Purpose|Purpose_indexed|Purpose_indexed_OHE|\n",
            "+--------------------+---------------+-------------------+\n",
            "|electronic equipment|            0.0|      (8,[0],[1.0])|\n",
            "|electronic equipment|            0.0|      (8,[0],[1.0])|\n",
            "|           education|            5.0|      (8,[5],[1.0])|\n",
            "|                FF&E|            2.0|      (8,[2],[1.0])|\n",
            "|         new vehicle|            1.0|      (8,[1],[1.0])|\n",
            "|           education|            5.0|      (8,[5],[1.0])|\n",
            "|                FF&E|            2.0|      (8,[2],[1.0])|\n",
            "|        used vehicle|            3.0|      (8,[3],[1.0])|\n",
            "|electronic equipment|            0.0|      (8,[0],[1.0])|\n",
            "|         new vehicle|            1.0|      (8,[1],[1.0])|\n",
            "|         new vehicle|            1.0|      (8,[1],[1.0])|\n",
            "|            business|            4.0|      (8,[4],[1.0])|\n",
            "|electronic equipment|            0.0|      (8,[0],[1.0])|\n",
            "|         new vehicle|            1.0|      (8,[1],[1.0])|\n",
            "|         new vehicle|            1.0|      (8,[1],[1.0])|\n",
            "|electronic equipment|            0.0|      (8,[0],[1.0])|\n",
            "|electronic equipment|            0.0|      (8,[0],[1.0])|\n",
            "|            business|            4.0|      (8,[4],[1.0])|\n",
            "|        used vehicle|            3.0|      (8,[3],[1.0])|\n",
            "|electronic equipment|            0.0|      (8,[0],[1.0])|\n",
            "+--------------------+---------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vector Assembler**"
      ],
      "metadata": {
        "id": "0UsfnpMR5MRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX9Ai8upQMMb",
        "outputId": "adca1d85-6f30-419c-9198-aed588bfdfb7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[loan_application_id: string, applicant_id: string, Months_loan_taken_for: string, Purpose: string, Principal_loan_amount: string, EMI_rate_in_percentage_of_disposable_income: string, Property: string, Has_coapplicant: string, Has_guarantor: string, Other_EMI_plans: string, Number_of_existing_loans_at_this_bank: string, Loan_history: string, high_risk_applicant: string, loan_application_id_indexed: double, applicant_id_indexed: double, Months_loan_taken_for_indexed: double, Purpose_indexed: double, Principal_loan_amount_indexed: double, EMI_rate_in_percentage_of_disposable_income_indexed: double, Property_indexed: double, Has_coapplicant_indexed: double, Has_guarantor_indexed: double, Other_EMI_plans_indexed: double, Number_of_existing_loans_at_this_bank_indexed: double, Loan_history_indexed: double]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vector Assembling to merge features and use them as a single identity**"
      ],
      "metadata": {
        "id": "E3e0FV_2EBXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "assembler = VectorAssembler(inputCols=['loan_application_id_indexed','applicant_id_indexed','Months_loan_taken_for_indexed','Purpose_indexed','Principal_loan_amount_indexed','EMI_rate_in_percentage_of_disposable_income_indexed','Property_indexed','Has_coapplicant_indexed','Has_guarantor_indexed','Other_EMI_plans_indexed','Number_of_existing_loans_at_this_bank_indexed','Loan_history_indexed' ] ,outputCol=\"features\")\n",
        "Vector=assembler.transform(df)\n"
      ],
      "metadata": {
        "id": "kP0W-46KaGkq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Vector.select('features').show(truncate=False)"
      ],
      "metadata": {
        "id": "LMfgXpDZ53tc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0c0be7cb-d372-43ef-eea0-ce41a108ab59"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-7ec180a46543>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mVector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    613\u001b[0m                 )\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_truncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o184.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 9.0 failed 1 times, most recent failure: Lost task 0.0 in stage 9.0 (TID 8) (69a785b24c96 executor driver): org.apache.spark.SparkException: Failed to execute user defined function (StringIndexerModel$$Lambda$3408/0x0000000841431040: (string) => double)\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.failedExecuteUserDefinedFunctionError(QueryExecutionErrors.scala:190)\n\tat org.apache.spark.sql.errors.QueryExecutionErrors.failedExecuteUserDefinedFunctionError(QueryExecutionErrors.scala)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.apache.spark.SparkException: StringIndexer encountered NULL value. To handle or skip NULLS, try setting StringIndexer.handleInvalid.\n\tat org.apache.spark.ml.feature.StringIndexerModel.$anonfun$getIndexer$1(StringIndexer.scala:396)\n\tat org.apache.spark.ml.feature.StringIndexerModel.$anonfun$getIndexer$1$adapted(StringIndexer.scala:391)\n\t... 17 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2268)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:506)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:459)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:48)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3868)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2863)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:3858)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3856)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3856)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2863)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:3084)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:288)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:327)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function (StringIndexerModel$$Lambda$3408/0x0000000841431040: (string) => double)\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.failedExecuteUserDefinedFunctionError(QueryExecutionErrors.scala:190)\n\tat org.apache.spark.sql.errors.QueryExecutionErrors.failedExecuteUserDefinedFunctionError(QueryExecutionErrors.scala)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\nCaused by: org.apache.spark.SparkException: StringIndexer encountered NULL value. To handle or skip NULLS, try setting StringIndexer.handleInvalid.\n\tat org.apache.spark.ml.feature.StringIndexerModel.$anonfun$getIndexer$1(StringIndexer.scala:396)\n\tat org.apache.spark.ml.feature.StringIndexerModel.$anonfun$getIndexer$1$adapted(StringIndexer.scala:391)\n\t... 17 more\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_df=Vector.select(\"features\", \"high_risk_applicant\")"
      ],
      "metadata": {
        "id": "UhE8JZSV8HHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_df.show()"
      ],
      "metadata": {
        "id": "08S1d8zh8NQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Importance**"
      ],
      "metadata": {
        "id": "Cz-BQYnf8Oc5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To define the important features that are affectig the most"
      ],
      "metadata": {
        "id": "gnW1ibipELM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "eeSHzrv98Ry6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa328817-3aa3-49fb-9022-ac8e71f54826"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[loan_application_id: string, applicant_id: string, Months_loan_taken_for: string, Purpose: string, Principal_loan_amount: string, EMI_rate_in_percentage_of_disposable_income: string, Property: string, Has_coapplicant: string, Has_guarantor: string, Other_EMI_plans: string, Number_of_existing_loans_at_this_bank: string, Loan_history: string, high_risk_applicant: string, loan_application_id_indexed: double, applicant_id_indexed: double, Months_loan_taken_for_indexed: double, Purpose_indexed: double, Principal_loan_amount_indexed: double, EMI_rate_in_percentage_of_disposable_income_indexed: double, Property_indexed: double, Has_coapplicant_indexed: double, Has_guarantor_indexed: double, Other_EMI_plans_indexed: double, Number_of_existing_loans_at_this_bank_indexed: double, Loan_history_indexed: double]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=df['loan_application_id_indexed','applicant_id_indexed','Months_loan_taken_for_indexed','Purpose_indexed','Principal_loan_amount_indexed','EMI_rate_in_percentage_of_disposable_income_indexed','Property_indexed','Has_coapplicant_indexed','Has_guarantor_indexed','Other_EMI_plans_indexed','Number_of_existing_loans_at_this_bank_indexed','Loan_history_indexed'].toPandas()\n",
        "# Creating Array structure\n",
        "y=df.select('high_risk_applicant').toPandas()\n"
      ],
      "metadata": {
        "id": "0OYN6s1f8UZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape\n",
        "y.shape"
      ],
      "metadata": {
        "id": "1a0Jvj55H5w0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separating Trainig and Testing data"
      ],
      "metadata": {
        "id": "8hyVTD-IEWYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.5, random_state =1, stratify = y)"
      ],
      "metadata": {
        "id": "_ikN0Z-ZH5qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "R51GDGO9aH81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical = [col for col in X_train.columns if X_train[col].dtypes == 'O']\n",
        "\n",
        "categorical"
      ],
      "metadata": {
        "id": "4W4DvSWzaJcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical = [col for col in X_train.columns if X_train[col].dtypes != 'O']\n",
        "\n",
        "numerical"
      ],
      "metadata": {
        "id": "VXhv1Q26aK0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filling nulls with mean"
      ],
      "metadata": {
        "id": "0alORERZElUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[numerical].isnull().mean()\n"
      ],
      "metadata": {
        "id": "84xxKUu9aK4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nomalizing the data"
      ],
      "metadata": {
        "id": "aWYRO1A8EnsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts(normalize=True)*100"
      ],
      "metadata": {
        "id": "iktFqilKaOM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.value_counts(normalize=True)*100"
      ],
      "metadata": {
        "id": "tSMo2nNNaRZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.isnull().sum()\n",
        "print()\n",
        "y_train.isnull().sum()\n",
        "print()\n",
        "X_test.isnull().sum()\n",
        "print()\n",
        "y_test.isnull().sum()\n"
      ],
      "metadata": {
        "id": "5vkZbVboaUZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Random Forest Classifier to build model here"
      ],
      "metadata": {
        "id": "HYgNbnEiEseK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc = RandomForestClassifier(random_state=0)\n"
      ],
      "metadata": {
        "id": "Gzm2-ygiaVlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfc.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "rGdPc2_RaZDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = rfc.predict(X_test)\n",
        "rfc_100 = RandomForestClassifier(n_estimators=100, random_state=0)"
      ],
      "metadata": {
        "id": "_BvG1d8CaZG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfc_100.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "3yVuYL9QaZK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_100 = rfc_100.predict(X_test)\n"
      ],
      "metadata": {
        "id": "4V0I5WYfafbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('Model accuracy score with 100 decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred_100)))"
      ],
      "metadata": {
        "id": "7o4PSt_RagdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "clf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "nsmx3EZyahdG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}